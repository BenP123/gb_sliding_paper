{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cu 003 processing ###\n",
    "\n",
    "\n",
    "#%% load the packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import defdap.hrdic as hrdic\n",
    "import defdap.ebsd as ebsd\n",
    "import defdap.experiment as experiment\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import copy \n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import os\n",
    "\n",
    "# get dictools stuff \n",
    "import sys\n",
    "sys.path.append(\"c:/Ben/Work/hrdic-tools/\")\n",
    "import dictools\n",
    "\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newtec_rigdata_read(rig_file_name,gauge_length,gauge_width,gauge_thickness):\n",
    "    # reads in the two key datafiles from Softstrain\n",
    "    # 1. csv file containing the rig data\n",
    "    # 2. log file containing imaging and step timings \n",
    "\n",
    "    # This function combines everything into one giant dataframe. Unfortunately the timestamps are different for the log and the csv so we have to do some \"filling\"\n",
    "\n",
    "    # Read the csv file \n",
    "    csv_file = rig_file_name + '.csv'\n",
    "    df_csv = pd.read_csv(csv_file)\n",
    "\n",
    "    # change to work with timestamps rather than \"Time\"\n",
    "    df_csv['Time stamp'] = pd.to_datetime(df_csv['Time'])\n",
    "\n",
    "    # get rid of these as metadata may be wrong meaning these are wrong\n",
    "    df_csv.drop(columns = ['Strain (%)','Stress (MPa)','Corrected Elongation (µm)','Corrected Strain (%)','Time'],inplace=True)\n",
    "\n",
    "\n",
    "    # Read log file \n",
    "    # read log file to get everything \n",
    "    log_file = rig_file_name + '_log.txt'\n",
    "    df_log = pd.read_csv(log_file,names=['Raw'])\n",
    "\n",
    "    # separate out lines into timestamps and content \n",
    "    df_log[['Time stamp','Text']] = df_log['Raw'].str.split(pat=r\"PROJECT|SEM MANAGER|TRACTION\",expand=True,regex=True)\n",
    "    df_log['Time stamp'] = df_log['Time stamp'].str.replace('[INFO] ','')\n",
    "\n",
    "    df_log['Time stamp'] = pd.to_datetime(df_log['Time stamp'])\n",
    "\n",
    "    # separate out SEM MANAGER lines \n",
    "    df_log['Type'] = None\n",
    "    df_log.loc[pd.notnull(df_log['Raw'].str.split(pat=r\"SEM MANAGER\",expand=True,regex=True)[1]),'Type'] = 'SEM MANAGER'\n",
    "\n",
    "    # separate out PROJECT lines\n",
    "    df_log.loc[pd.notnull(df_log['Raw'].str.split(pat=r\"PROJECT\",expand=True,regex=True)[1]),'Type'] = 'PROJECT'\n",
    "\n",
    "    # separate out PROJECT lines\n",
    "    df_log.loc[pd.notnull(df_log['Raw'].str.split(pat=r\"TRACTION\",expand=True,regex=True)[1]),'Type'] = 'TRACTION'\n",
    "\n",
    "    \n",
    "    # Join the two dataframes together\n",
    "    # join everything together\n",
    "    df_mega = pd.concat([df_csv,df_log])\n",
    "\n",
    "    # sort so timestamps increase monotonically\n",
    "    df_mega = df_mega.sort_values('Time stamp')\n",
    "\n",
    "    # reindex to destroy old indices from previous dataframes\n",
    "    df_mega = df_mega.reset_index(drop=True)\n",
    "\n",
    "    # tidy up some unnecessary columns\n",
    "    df_mega = df_mega.drop(columns = ['Raw',\n",
    "                                    'Elapsed Time (s)',\n",
    "                                    'LVDT Position (µm)'])\n",
    "\n",
    "\n",
    "\n",
    "    # fill in blanks for timestamps that don't match imaging timestamps \n",
    "    # backfill first\n",
    "    df_mega['Position (µm)']            = df_mega['Position (µm)'].bfill()\n",
    "    df_mega['Elongation (µm)']          = df_mega['Elongation (µm)'].bfill()\n",
    "    df_mega['Force (N)']                = df_mega['Force (N)'].bfill()\n",
    "    df_mega['Step']                     = df_mega['Step'].bfill()\n",
    "    df_mega['Sample Temperature (°C)']  = df_mega['Sample Temperature (°C)'].bfill()\n",
    "\n",
    "    \n",
    "\n",
    "    # then foward fill to deal with the very end\n",
    "    df_mega['Position (µm)']            = df_mega['Position (µm)'].ffill()\n",
    "    df_mega['Elongation (µm)']          = df_mega['Elongation (µm)'].ffill()\n",
    "    df_mega['Force (N)']                = df_mega['Force (N)'].ffill()\n",
    "    df_mega['Step']                     = df_mega['Step'].ffill()\n",
    "    df_mega['Sample Temperature (°C)']  = df_mega['Sample Temperature (°C)'].ffill()\n",
    "\n",
    "\n",
    "    # calculate stress and strain measures \n",
    "    gauge_csa = gauge_width*gauge_thickness*1e-6 # m^2\n",
    "    df_mega['Eng Stress / MPa']  = df_mega['Force (N)']*1e-6/gauge_csa\n",
    "    df_mega['Eng Strain / - ']   = (df_mega['Elongation (µm)']-df_mega['Elongation (µm)'].iloc[0])*1e-3 / gauge_length\n",
    "\n",
    "    df_mega['True Stress / MPa'] = df_mega['Eng Stress / MPa']*(1 + df_mega['Eng Strain / - '])\n",
    "    df_mega['True Strain / - ']  = np.log(1+df_mega['Eng Strain / - '])\n",
    "\n",
    "    # add one to steps as (for some unknown reason), Softstrain starts at -1\n",
    "    df_mega['Step'] = df_mega['Step'] + 1\n",
    "\n",
    "    # make a new elapsed time column\n",
    "    t_delta = df_mega['Time stamp']- df_mega['Time stamp'].iloc[0]\n",
    "\n",
    "    # convert to seconds. Pandas by default goes to nanoseconds so convert to seconds\n",
    "    t_delta = 1e-9*pd.to_numeric(t_delta)\n",
    "    df_mega['Elapsed Time (s)'] = t_delta\n",
    "\n",
    "\n",
    "    # find imaging steps\n",
    "    df_mega['Imaging step'] = False \n",
    "    df_mega['Imaging start'] = False\n",
    "\n",
    "    for i in range(0,np.asarray(df_mega['Step'].unique(),dtype=int)[-1]+1):\n",
    "        this_step = df_mega[df_mega['Step'] == i] \n",
    "\n",
    "        # word that triggers this is \"Acquisition\" - find first occurence\n",
    "        try:\n",
    "            # checks if step contains an \"Acquisition\"\n",
    "            idx = this_step['Text'][this_step['Text'].str.contains('Acquisition',na=False)].index[0]\n",
    "\n",
    "            # sets imaging step boolean to true if there is an acquisition\n",
    "            df_mega['Imaging step'] = df_mega['Imaging step'].mask(df_mega['Step'] == i,True)\n",
    "\n",
    "            # sets imaging start boolean to true for time stamp of imaging start\n",
    "            df_mega.at[idx,'Imaging start'] = True\n",
    "\n",
    "        except:\n",
    "            # not an imaging step so we can ignore \n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plot a figure to show the test profiles\n",
    "    fig = plt.figure()\n",
    "\n",
    "    fig.set_size_inches(12, 7)\n",
    "\n",
    "    # set up grid \n",
    "    gs0 = gridspec.GridSpec(nrows=1,ncols=2,figure=fig,width_ratios=[1,3])\n",
    "    gs00 =gridspec.GridSpecFromSubplotSpec(nrows=3,ncols=1,subplot_spec=gs0[0])\n",
    "    gs01 =gridspec.GridSpecFromSubplotSpec(nrows=1,ncols=1,subplot_spec=gs0[1:])\n",
    "\n",
    "    ax_small = gs00.subplots(sharex=True)\n",
    "\n",
    "    ax_big = fig.add_subplot(gs01[0])\n",
    "\n",
    "    for i in range(0,np.asarray(df_mega['Step'].unique(),dtype=int)[-1]+1):\n",
    "        this_step = df_mega[df_mega['Step'] == i]\n",
    "\n",
    "        #plot time as elapsed from start \n",
    "\n",
    "        # force - time\n",
    "        ax_small[0].plot(this_step['Elapsed Time (s)']/3600,this_step['Force (N)'])\n",
    "\n",
    "        # elongation - time\n",
    "        ax_small[1].plot(this_step['Elapsed Time (s)']/3600,this_step['Elongation (µm)'])\n",
    "\n",
    "        # Temperature - time\n",
    "        ax_small[2].plot(this_step['Elapsed Time (s)']/3600,this_step['Sample Temperature (°C)'])\n",
    "\n",
    "        # Engineering stress - engineering strain\n",
    "        ax_big.plot(this_step['Eng Strain / - '],this_step['Eng Stress / MPa'])\n",
    "\n",
    "        # plot markers for when imaging starts \n",
    "        im_start = this_step[this_step['Imaging start'] == True]\n",
    "        ax_big.plot(im_start['Eng Strain / - '],im_start['Eng Stress / MPa'],'kx')\n",
    "\n",
    "        # add annotation for step number\n",
    "        try:\n",
    "            x0 = im_start['Eng Strain / - '].to_numpy()[0]\n",
    "            y0 = im_start['Eng Stress / MPa'].to_numpy()[0]\n",
    "            dx = 0.0005\n",
    "            dy = -10\n",
    "            \n",
    "            ax_big.annotate(str(i),xy = (x0,y0), xytext = (x0+dx,y0+dy),arrowprops=dict(width=1,facecolor='black',headwidth=10,headlength=15))\n",
    "        except: \n",
    "            pass\n",
    "\n",
    "    # label it all up\n",
    "    fig.suptitle('Test profile')\n",
    "\n",
    "    # time dependent graphs\n",
    "    ax_small[-1].set_xlabel('Time / hours')\n",
    "\n",
    "    ax_small[0].set_ylabel('Force / N')\n",
    "    ax_small[1].set_ylabel('Elongation (µm)')\n",
    "    ax_small[2].set_ylabel('Sample Temperature (°C)')\n",
    "\n",
    "    # flow curve\n",
    "    ax_big.set_xlabel('Engineering strain / -')\n",
    "    ax_big.set_ylabel('Engineering Stress / MPa')\n",
    "\n",
    "    # switch grids on \n",
    "    for ax in ax_small: ax.grid()\n",
    "    ax_big.grid()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "    return df_mega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_length = 12.0      # mm\n",
    "gauge_width = 1.5        # mm\n",
    "gauge_thickness = 1.006 # mm\n",
    "rig_data_file = './ofhc_cu_5pc'\n",
    "\n",
    "\n",
    "df = newtec_rigdata_read('./ofhc_cu_5pc',gauge_length,gauge_width,gauge_thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_step = df[df['Step'] == 19]\n",
    "im_start = this_step[this_step['Imaging start'] == True]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = experiment.Experiment()\n",
    "\n",
    "dic_dir = Path('./DIC/')\n",
    "ebsd_pre_dir = Path('./Pre_EBSD/')\n",
    "ebsd_post_dir = Path('./Post_EBSD/')\n",
    "\n",
    "dic_frame = experiment.Frame()\n",
    "for dic_file in sorted(dic_dir.glob('map_*.txt')):\n",
    "    hrdic.Map(dic_file, experiment=exp, frame=dic_frame,data_type='openpiv')\n",
    "    \n",
    "hfw = 20.0 # microns\n",
    "pixelwidth = 2048\n",
    "pixelsize = hfw/pixelwidth\n",
    "\n",
    "for inc, dic_map in exp.iter_over_maps('hrdic'):\n",
    "    dic_map.set_scale(pixelsize)\n",
    "    dic_map.set_crop(left=100,right=100,top=100,bottom=100)\n",
    "    # dic_map.plot_map('max_shear',vmin=0,vmax=0.01,plot_scale_bar=True)\n",
    "    print(dic_map)\n",
    "    \n",
    "ebsd_pre_frame = experiment.Frame()\n",
    "ebsd.Map(ebsd_pre_dir / 'map.cpr',increment=exp.increments[0], frame=ebsd_pre_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_map = exp.increments[-1].maps['hrdic']\n",
    "dic_map.set_homog_point(vmin=0,vmax=0.2)\n",
    "\n",
    "ebsd_map = exp.increments[0].maps['ebsd']\n",
    "ebsd_map.set_homog_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebsd_pre_frame.homog_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_frame.homog_points = [(1722, 1177),\n",
    " (1335, 1313),\n",
    " (948, 1745),\n",
    " (549, 1661),\n",
    " (245, 1680),\n",
    " (233, 1300),\n",
    " (579, 1158),\n",
    " (443, 756),\n",
    " (559, 136),\n",
    " (83, 359),\n",
    " (1438, 495),\n",
    " (857, 165)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebsd_pre_frame.homog_points = [(2541, 1823),\n",
    " (2240, 1932),\n",
    " (1940, 2266),\n",
    " (1631, 2207),\n",
    " (1394, 2225),\n",
    " (1388, 1933),\n",
    " (1659, 1820),\n",
    " (1554, 1519),\n",
    " (1648, 1054),\n",
    " (1279, 1219),\n",
    " (2323, 1319),\n",
    " (1875, 1080)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # plot maps\n",
    "for inc, dic_map in exp.iter_over_maps('hrdic'):\n",
    "    dic_map.set_crop\n",
    "    dic_map.link_ebsd_map(ebsd_map, transform_type=\"polynomial\",order=2)\n",
    "    # dic_map.plot_map(\n",
    "    #     'max_shear', vmin=0, vmax=0.10, \n",
    "    #     plot_scale_bar=False, plot_gbs='line'\n",
    "    # )\n",
    "    # plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max force times \n",
    "force = df['Force (N)']\n",
    "\n",
    "df['Max force in step'] = False\n",
    "df['Imaging start'] = False\n",
    "df['Imaging now'] = False\n",
    "\n",
    "for i in imaging_step_numbers:\n",
    "    this_step = df[df['Step'] == i]\n",
    "\n",
    "    # find max force from cycle\n",
    "    try:\n",
    "        idx = this_step['Force (N)'].idxmax()\n",
    "    except: \n",
    "        print('Test failed on step ' +str(i) + ' so we will ignore it')\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.plot(this_step['Elapsed Time (s)'],this_step['Force (N)'])\n",
    "    # plt.plot(this_step['Elapsed Time (s)'].iloc[0],this_step['Force (N)'].iloc[0],'+')\n",
    "    # plt.plot(this_step['Elapsed Time (s)'].loc[idx],this_step['Force (N)'].loc[idx],'+')\n",
    "\n",
    "    df.loc[idx,['Max force in step']] = True\n",
    "\n",
    "    # find imaging start time \n",
    "    \n",
    "    # find mean time increment for step\n",
    "    t_step = np.nanmean(np.diff(this_step['Elapsed Time (s)']))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = imaging_maxforce_df['Elapsed Time (s)'].to_numpy()+imaging_wait_time # <------ this might not work given we only wait on some steps! will need the metadata from the raw images to get this\n",
    "t2 = np.isclose(df['Elapsed Time (s)'],t1[0],atol=0.5) \n",
    "df[t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times,'+')\n",
    "plt.plot(image_start_time,'+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(imaging_starts_df['Eng Strain / - '],imaging_starts_df['Eng Stress / MPa'],'+')\n",
    "plt.plot(imaging_maxforce_df['Eng Strain / - '],imaging_maxforce_df['Eng Stress / MPa'],'x')\n",
    "plt.plot(df['Eng Strain / - '],df['Eng Stress / MPa'],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvar = 'Elapsed Time (s)'\n",
    "yvar = 'Eng Stress / MPa'\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(imaging_starts_df[xvar],imaging_starts_df[yvar],'+')\n",
    "plt.plot(imaging_maxforce_df[xvar],imaging_maxforce_df[yvar],'x')\n",
    "plt.plot(df[xvar],df[yvar],'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openPIVbatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
